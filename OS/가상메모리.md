# 가상 메모리

## 배경

* 프로세스가 실행되는 코드의 전체를 메모리에 로드해야 했고, 메모리 용량보다 더 큰 프로그램은 실행시킬 수 X 
* 하지만 실제로는 코드의 일부에서만 대부분의 시간을 사용하고, 프로세스는 특정 순간에는 항상 작은 양의 주소 공간을 사용했기 때문에 이러한 방식은 매우 비효율적!
 

## 가상메모리란?

> 메모리가 실제 메모리보다 많아 보이게 하는 기술

* 어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하다는 점에 착안하여 고안 -> 물리적 메모리 크기의 한계를 극복
* 애플리케이션이 실행 시 실행에 필요한 일부분만 메모리에 올라가며 애플리케이션의 나머지는 디스크에 남게 됨 -> 디스크가 RAM의 보조 기억장치처럼 작동
  * 결국 빠르고 작은 기억장치(RAM)을 크고 느린 기억장치(디스크)와 병합하여, 하나의 크고 빠른 기억장치(가상 메모리)처럼 동작하게 하는 것
  * 이처럼 현재 필요한 page만 메모리에 올리는 것을 ```Demand Paging```이라 함
* 가상 메모리를 구현하기 위해서는 컴퓨터가 특수 메모리 관리 하드웨어를 갖추고 있어야만 함 ⇒ 바로 ```MMU(Memory Management Unit)```

### MMU

* MMU는 가상주소를 물리주소로 변환하고, 메모리를 보호하는 기능을 수행함.
* MMU를 사용하게 되면, CPU가 각 메모리에 접근하기 이전에 메모리 주소 번역 작업이 수행됨.
* 그러나 메모리를 일일이 가상 주소에서 물리적 주소로 번역하게 되면 작업 부하가 너무 높아지므로, MMU는 RAM을 여러 부분(페이지, pages)로 나누어 각 페이지를 하나의 독립된 항목으로 처리함.
* 페이지 및 주소 번역 정보를 기억하는 작업이 가상 메모리를 구현하는 데 있어 결정적인 절차임.

## Demand Paging(요구 페이징)

> 실제로 필요할 때 page를 메모리에 올리는 것

<img width="600" alt="스크린샷 2022-11-01 오전 1 46 01" src="https://user-images.githubusercontent.com/97823928/199062675-1e41930d-e051-43bd-9503-54481031bdfc.png">

* page table에서 해당 page가 메모리에 있는지를 나타내는 valid-invalid bit를 사용 -> bit가 invalid인 경우 페이지가 물리적 메모리에 없다는 것
* 처음에는 모든 page entry가 invalid로 초기화되어있고, 주소 변환 시 bit가 invalid로 되어있다면 page fault라는 오류가 발생

### 과정
1. 하드웨어가 TLB를 확인한다.
2. TLB hit인 경우 곧바로 주소를 변환하고, TLB miss인 경우 page table을 확인한다(→3). 
3. page table의 valid-invalid bit가 valid로 되어 있다면 주소를 변환하고 TLB에 page를 올린다. invalid라면 page fault가 발생한다(→4). 
4. page fault가 발생하면 MMU가 운영체제에 Trap을 걸고 커널 모드로 들어가서 page fault handler가 invoke된다.
5. 유효하지 않은 참조인 경우 프로세스를 종료시키고, 그렇지 않다면 빈 page frame을 얻는다. 빈 frame이 없다면 메모리에서 victim page를 선택하여 대체한다.  
6. 운영체제는 참조된 page를 디스크에서 메모리로 로드(I/O)하고, disk I/O가 끝날 때까지 이 프로세스는 CPU를 빼앗긴다.
7. disk I/O가 끝나면 page table이 업데이트되고 valid-invalid bit가 valid로 바뀐다. 그리고 ready queue에 프로세스를 넣어준다.  
8. 프로세스가 CPU를 잡게 되면 다시 이어서 수행한다. 

```
# 용어정리

1. TLB (Translation Look-aside Buffer)

page table는 메인 메모리에 존재 -> CPU는 메인 메모리에 최소 2번은 접근해야 원하는 데이터를 얻을 수 있음
 1) page table에 한번 접근
 2) page table을 기반으로 실제 메모리로 접근
 
* 이러한 메모리의 접근을 줄이고자 나온 게 TLB 
* 하드웨어적으로 지원하여 page table의 임시저장 cache 역할을 한다. 
* TLB는 최근에 읽었던 page table을 매핑하여 저장하는데 굉장히 작다. 
  * 64 ~ 1024 entry정도
  * 왜냐면 TLB에 있으면 메모리에 접근하기 전에 막아야 하기 때문에 크기를 작게 하여 속도를 높임
* CPU에서 나온 정보를 가지고 TLB를 탐색하고, 있다면 바로 물리 주소에 접근하고, 없다면 page table로 들어간다. 
```

## 페이지 교체 알고리즘

> 메모리에 빈 프레임이 없을 때 적재될 페이지를 위해 적재된 페이지 중 어떠한 것이 교체 대상이 될 것인가 ?

### 1. OPT(Optimal Algorithm)

> 가장 오랫동안 참조되지 않을 페이지를 선택하여 교체하는 기법

<img width="600" alt="스크린샷 2022-11-01 오전 2 09 29" src="https://user-images.githubusercontent.com/97823928/199067360-0e772bc1-c75d-4718-b167-513c70bfb1f1.png">

교체에 있어서 최고의 선택은 페이지 부재를 최소화하는 것 -> ```가장 오랫동안 참조되지 않을 페이지```를 선택하여 교체하는 방법
* 페이지 부재를 최소화하지만 프로세스들이 앞으로 어떠한 페이지들을 참조할지 미리 알 수 없으므로 현실적인 구현은 불가능함
* 간단 설명 : 적재된 페이지와 동일한 참조열인 경우에만 페이지 부재가 발생하지 않음


### 2. FIFO(First In First Out) Algorithm

> 적재된지 가장 오래된 페이지를 교체하는 기법

<img width="600" alt="스크린샷 2022-11-01 오전 2 13 28" src="https://user-images.githubusercontent.com/97823928/199068113-2613f8f2-af24-4eb6-bf43-ed0a15b5cb82.png">

```
근데 적재된 시간이나 순서를 어떻게 알아냄??
1. 시간기록 기법
* 각 페이지가 적재될 떄의 시간을 기록한 후 교체 시 이 시간이 가장 오래전인 페이지를 선택
* 하지만 시간 기록을 위한 추가 기억장소와 시간들을 비교하는 오버헤드가 불가피함

2. 큐 이용
* 교체의 대상은 항상 큐의 맨 앞이 되도록 유지, 관리하는 것
* 이 방식은 교체 대상을 바로 알 수 있으나 큐 내에세 페이지를 자리 잡아주는데 걸리는 오버헤드가 발생
```

### 3.LRU (Least Recently Used) Algorithm

> 참조된지 가장 오래된 페이지를 교체하는 기법

<img width="770" alt="스크린샷 2022-11-01 오전 2 17 33" src="https://user-images.githubusercontent.com/97823928/199068952-28ed8c54-404a-41ce-b66d-c7971899bd50.png">

* 스택의 가장 밑에 있는 페이지가 교체 대상이 되도록 함
* 참조된 걸 교체하되 가장 오래된걸 아래로 보낸다!

### 4. LFU(Least Frequently Used) Algorithm
